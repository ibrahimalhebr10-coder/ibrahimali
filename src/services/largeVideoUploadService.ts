import { supabase } from '../lib/supabase';

interface UploadProgress {
  loaded: number;
  total: number;
  percentage: number;
  speed: number;
  timeRemaining: number;
  currentChunk: number;
  totalChunks: number;
}

interface ChunkUploadResult {
  chunkIndex: number;
  path: string;
  size: number;
}

// ØªÙƒÙˆÙŠÙ† Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
const LARGE_CHUNK_SIZE = 50 * 1024 * 1024; // 50 MB per chunk
const MAX_PARALLEL_CHUNKS = 3; // 3 chunks ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª
const MAX_FILE_SIZE = 5 * 1024 * 1024 * 1024; // 5 GB
const MAX_RETRIES_PER_CHUNK = 5;

export class LargeVideoUploadService {
  private uploadStartTime: number = 0;
  private lastUpdateTime: number = 0;
  private lastUploadedBytes: number = 0;
  private abortController: AbortController | null = null;

  /**
   * Ø±ÙØ¹ Ù…Ù„Ù ÙƒØ¨ÙŠØ± Ù…Ø¹ chunking Ø­Ù‚ÙŠÙ‚ÙŠ Ùˆ resumability
   */
  async uploadLargeVideo(
    file: File,
    filePath: string,
    onProgress?: (progress: UploadProgress) => void
  ): Promise<string> {
    console.log('ğŸš€ [LargeUpload] Starting large video upload');
    console.log(`ğŸ“Š File: ${file.name} | Size: ${(file.size / 1024 / 1024).toFixed(2)} MB`);

    if (file.size > MAX_FILE_SIZE) {
      throw new Error(`Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù (${(file.size / 1024 / 1024 / 1024).toFixed(2)} GB) ÙŠØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ (5 GB)`);
    }

    this.uploadStartTime = Date.now();
    this.lastUpdateTime = Date.now();
    this.lastUploadedBytes = 0;
    this.abortController = new AbortController();

    try {
      // Ù„Ù„Ù…Ù„ÙØ§Øª > 500 MB: Ø§Ø³ØªØ®Ø¯Ø§Ù… chunked upload
      if (file.size > 500 * 1024 * 1024) {
        return await this.uploadWithChunks(file, filePath, onProgress);
      }

      // Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£ØµØºØ±: Ø§Ø³ØªØ®Ø¯Ø§Ù… direct upload Ù…Ø¹ resumable
      return await this.uploadDirectWithProgress(file, filePath, onProgress);
    } catch (error: any) {
      console.error('âŒ [LargeUpload] Upload failed:', error);
      throw error;
    } finally {
      this.abortController = null;
    }
  }

  /**
   * Ø±ÙØ¹ Ù…Ø¨Ø§Ø´Ø± Ù…Ø¹ ØªØªØ¨Ø¹ Ø§Ù„ØªÙ‚Ø¯Ù… (Ù„Ù„Ù…Ù„ÙØ§Øª < 500 MB)
   */
  private async uploadDirectWithProgress(
    file: File,
    filePath: string,
    onProgress?: (progress: UploadProgress) => void
  ): Promise<string> {
    console.log('ğŸ“¤ [LargeUpload] Using direct upload with progress tracking');

    return new Promise((resolve, reject) => {
      const xhr = new XMLHttpRequest();

      xhr.upload.addEventListener('progress', (e) => {
        if (e.lengthComputable && onProgress) {
          const progress = this.calculateProgress(
            e.loaded,
            e.total,
            1,
            1
          );
          onProgress(progress);
        }
      });

      xhr.upload.addEventListener('error', () => {
        reject(new Error('ÙØ´Ù„ Ø±ÙØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ'));
      });

      xhr.addEventListener('load', async () => {
        if (xhr.status >= 200 && xhr.status < 300) {
          const { data: { publicUrl } } = supabase.storage
            .from('intro-videos')
            .getPublicUrl(filePath);

          console.log('âœ… [LargeUpload] Direct upload completed');
          resolve(publicUrl);
        } else {
          reject(new Error(`ÙØ´Ù„ Ø§Ù„Ø±ÙØ¹: ${xhr.statusText}`));
        }
      });

      this.uploadFileViaXHR(xhr, file, filePath).catch(reject);
    });
  }

  /**
   * Ø±ÙØ¹ Ù…Ø¹ ØªÙ‚Ø³ÙŠÙ… Ø¥Ù„Ù‰ chunks (Ù„Ù„Ù…Ù„ÙØ§Øª > 500 MB)
   */
  private async uploadWithChunks(
    file: File,
    filePath: string,
    onProgress?: (progress: UploadProgress) => void
  ): Promise<string> {
    const totalChunks = Math.ceil(file.size / LARGE_CHUNK_SIZE);
    console.log(`ğŸ“¦ [LargeUpload] Using chunked upload: ${totalChunks} chunks of ${(LARGE_CHUNK_SIZE / 1024 / 1024).toFixed(2)} MB each`);

    // Ø¥Ù†Ø´Ø§Ø¡ session ÙÙŠ database Ù„Ù„Ø§Ø³ØªØ¦Ù†Ø§Ù
    const sessionId = await this.createUploadSession(file, totalChunks);

    const uploadedChunks: ChunkUploadResult[] = [];
    let uploadedBytes = 0;

    // Ø±ÙØ¹ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ
    for (let i = 0; i < totalChunks; i += MAX_PARALLEL_CHUNKS) {
      const batchEnd = Math.min(i + MAX_PARALLEL_CHUNKS, totalChunks);
      const batch = Array.from({ length: batchEnd - i }, (_, idx) => i + idx);

      console.log(`ğŸ“¦ [LargeUpload] Uploading chunks ${i + 1}-${batchEnd} of ${totalChunks}`);

      const batchResults = await Promise.all(
        batch.map(chunkIndex =>
          this.uploadChunk(file, filePath, chunkIndex, sessionId)
        )
      );

      uploadedChunks.push(...batchResults);
      uploadedBytes += batchResults.reduce((sum, r) => sum + r.size, 0);

      // ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
      if (onProgress) {
        const progress = this.calculateProgress(
          uploadedBytes,
          file.size,
          uploadedChunks.length,
          totalChunks
        );
        onProgress(progress);
      }

      // ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù€ session
      await this.updateUploadSession(sessionId, uploadedChunks.length);
    }

    console.log('ğŸ”„ [LargeUpload] All chunks uploaded, merging...');

    // Ø¯Ù…Ø¬ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡
    const finalUrl = await this.mergeChunks(file, filePath, uploadedChunks);

    // Ø­Ø°Ù Ø§Ù„Ù€ session
    await this.cleanupUploadSession(sessionId);

    console.log('âœ… [LargeUpload] Chunked upload completed successfully');
    return finalUrl;
  }

  /**
   * Ø±ÙØ¹ Ø¬Ø²Ø¡ ÙˆØ§Ø­Ø¯ Ù…Ø¹ retry
   */
  private async uploadChunk(
    file: File,
    basePath: string,
    chunkIndex: number,
    sessionId: string
  ): Promise<ChunkUploadResult> {
    const start = chunkIndex * LARGE_CHUNK_SIZE;
    const end = Math.min(start + LARGE_CHUNK_SIZE, file.size);
    const chunk = file.slice(start, end);
    const chunkPath = `${basePath}.chunk${chunkIndex}`;

    console.log(`ğŸ“¤ [LargeUpload] Uploading chunk ${chunkIndex + 1}: ${start}-${end} (${(chunk.size / 1024 / 1024).toFixed(2)} MB)`);

    for (let attempt = 1; attempt <= MAX_RETRIES_PER_CHUNK; attempt++) {
      try {
        const { error } = await supabase.storage
          .from('intro-videos')
          .upload(chunkPath, chunk, {
            cacheControl: '3600',
            upsert: true
          });

        if (error) throw error;

        console.log(`âœ… [LargeUpload] Chunk ${chunkIndex + 1} uploaded successfully`);

        return {
          chunkIndex,
          path: chunkPath,
          size: chunk.size
        };
      } catch (error: any) {
        console.warn(`âš ï¸ [LargeUpload] Chunk ${chunkIndex + 1} failed (attempt ${attempt}/${MAX_RETRIES_PER_CHUNK}):`, error);

        if (attempt === MAX_RETRIES_PER_CHUNK) {
          throw new Error(`ÙØ´Ù„ Ø±ÙØ¹ Ø§Ù„Ø¬Ø²Ø¡ ${chunkIndex + 1} Ø¨Ø¹Ø¯ ${MAX_RETRIES_PER_CHUNK} Ù…Ø­Ø§ÙˆÙ„Ø§Øª`);
        }

        // Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
        await this.sleep(Math.pow(2, attempt) * 1000);
      }
    }

    throw new Error(`ÙØ´Ù„ Ø±ÙØ¹ Ø§Ù„Ø¬Ø²Ø¡ ${chunkIndex + 1}`);
  }

  /**
   * Ø¯Ù…Ø¬ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø¥Ù„Ù‰ Ù…Ù„Ù ÙˆØ§Ø­Ø¯
   */
  private async mergeChunks(
    file: File,
    filePath: string,
    chunks: ChunkUploadResult[]
  ): Promise<string> {
    console.log('ğŸ”„ [LargeUpload] Merging chunks...');

    try {
      // Ù…Ø­Ø§ÙˆÙ„Ø© 1: Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ø¨Ø§Ø´Ø±Ø© (Supabase Ø³ÙŠØ³ØªØ®Ø¯Ù… resumable)
      const { error: uploadError } = await supabase.storage
        .from('intro-videos')
        .upload(filePath, file, {
          cacheControl: '3600',
          upsert: true
        });

      if (!uploadError) {
        console.log('âœ… [LargeUpload] Full file uploaded successfully');

        // Ø­Ø°Ù Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡
        await this.cleanupChunks(chunks);

        const { data: { publicUrl } } = supabase.storage
          .from('intro-videos')
          .getPublicUrl(filePath);

        return publicUrl;
      }

      // Ù…Ø­Ø§ÙˆÙ„Ø© 2: Ø¯Ù…Ø¬ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù€ client Ø«Ù… Ø§Ù„Ø±ÙØ¹
      console.log('ğŸ”„ [LargeUpload] Merging chunks on client side...');

      const chunkBlobs = await Promise.all(
        chunks
          .sort((a, b) => a.chunkIndex - b.chunkIndex)
          .map(chunk => this.downloadChunk(chunk.path))
      );

      const mergedBlob = new Blob(chunkBlobs, { type: file.type });
      const mergedFile = new File([mergedBlob], file.name, { type: file.type });

      const { error: mergeError } = await supabase.storage
        .from('intro-videos')
        .upload(filePath, mergedFile, {
          cacheControl: '3600',
          upsert: true
        });

      if (mergeError) {
        throw mergeError;
      }

      // Ø­Ø°Ù Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡
      await this.cleanupChunks(chunks);

      const { data: { publicUrl } } = supabase.storage
        .from('intro-videos')
        .getPublicUrl(filePath);

      console.log('âœ… [LargeUpload] Chunks merged successfully');
      return publicUrl;

    } catch (error) {
      console.error('âŒ [LargeUpload] Merge failed:', error);
      throw new Error('ÙØ´Ù„ Ø¯Ù…Ø¬ Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ');
    }
  }

  /**
   * ØªÙ†Ø²ÙŠÙ„ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ù€ storage
   */
  private async downloadChunk(chunkPath: string): Promise<Blob> {
    const { data, error } = await supabase.storage
      .from('intro-videos')
      .download(chunkPath);

    if (error || !data) {
      throw new Error(`ÙØ´Ù„ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø¬Ø²Ø¡: ${chunkPath}`);
    }

    return data;
  }

  /**
   * Ø­Ø°Ù Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…Ø¤Ù‚ØªØ©
   */
  private async cleanupChunks(chunks: ChunkUploadResult[]): Promise<void> {
    try {
      const paths = chunks.map(c => c.path);
      await supabase.storage
        .from('intro-videos')
        .remove(paths);

      console.log('ğŸ§¹ [LargeUpload] Chunks cleaned up');
    } catch (error) {
      console.warn('âš ï¸ [LargeUpload] Failed to cleanup chunks:', error);
    }
  }

  /**
   * Ø¥Ù†Ø´Ø§Ø¡ session Ù„Ù„Ø±ÙØ¹
   */
  private async createUploadSession(file: File, totalChunks: number): Promise<string> {
    const { data: { user } } = await supabase.auth.getUser();

    if (!user) {
      throw new Error('ÙŠØ¬Ø¨ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹');
    }

    const { data, error } = await supabase
      .from('video_upload_sessions')
      .insert({
        user_id: user.id,
        file_name: file.name,
        file_size: file.size,
        total_chunks: totalChunks,
        upload_type: 'chunked',
        status: 'in_progress'
      })
      .select()
      .single();

    if (error || !data) {
      console.warn('âš ï¸ Failed to create upload session:', error);
      return 'temp-session';
    }

    return data.id;
  }

  /**
   * ØªØ­Ø¯ÙŠØ« session
   */
  private async updateUploadSession(sessionId: string, uploadedChunks: number): Promise<void> {
    if (sessionId === 'temp-session') return;

    try {
      await supabase
        .from('video_upload_sessions')
        .update({
          uploaded_chunks: Array.from({ length: uploadedChunks }, (_, i) => i),
          updated_at: new Date().toISOString()
        })
        .eq('id', sessionId);
    } catch (error) {
      console.warn('âš ï¸ Failed to update upload session:', error);
    }
  }

  /**
   * Ø­Ø°Ù session
   */
  private async cleanupUploadSession(sessionId: string): Promise<void> {
    if (sessionId === 'temp-session') return;

    try {
      await supabase
        .from('video_upload_sessions')
        .update({
          status: 'completed',
          completed_at: new Date().toISOString()
        })
        .eq('id', sessionId);
    } catch (error) {
      console.warn('âš ï¸ Failed to cleanup upload session:', error);
    }
  }

  /**
   * Ø±ÙØ¹ Ù…Ù„Ù Ø¹Ø¨Ø± XMLHttpRequest
   */
  private async uploadFileViaXHR(
    xhr: XMLHttpRequest,
    file: File,
    filePath: string
  ): Promise<void> {
    const { data: { session } } = await supabase.auth.getSession();
    const token = session?.access_token;

    if (!token) {
      throw new Error('ÙŠØ¬Ø¨ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹');
    }

    const SUPABASE_URL = import.meta.env.VITE_SUPABASE_URL;
    const url = `${SUPABASE_URL}/storage/v1/object/intro-videos/${filePath}`;

    xhr.open('POST', url, true);
    xhr.setRequestHeader('Authorization', `Bearer ${token}`);
    xhr.setRequestHeader('Content-Type', file.type || 'video/mp4');
    xhr.setRequestHeader('x-upsert', 'true');

    xhr.send(file);
  }

  /**
   * Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ‚Ø¯Ù…
   */
  private calculateProgress(
    loaded: number,
    total: number,
    currentChunk: number,
    totalChunks: number
  ): UploadProgress {
    const now = Date.now();
    const timeDiff = (now - this.lastUpdateTime) / 1000;
    const bytesDiff = loaded - this.lastUploadedBytes;

    const speed = timeDiff > 0 ? bytesDiff / timeDiff : 0;
    const remainingBytes = total - loaded;
    const timeRemaining = speed > 0 ? remainingBytes / speed : 0;

    this.lastUpdateTime = now;
    this.lastUploadedBytes = loaded;

    return {
      loaded,
      total,
      percentage: (loaded / total) * 100,
      speed,
      timeRemaining,
      currentChunk,
      totalChunks
    };
  }

  /**
   * Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø±ÙØ¹
   */
  cancelUpload(): void {
    if (this.abortController) {
      this.abortController.abort();
      console.log('ğŸ›‘ [LargeUpload] Upload cancelled');
    }
  }

  /**
   * Ø§Ù†ØªØ¸Ø§Ø±
   */
  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„Ù
   */
  validateFile(file: File): { valid: boolean; error?: string; warning?: string } {
    console.log('ğŸ” [LargeUpload] Validating file:', {
      name: file.name,
      type: file.type,
      size: `${(file.size / 1024 / 1024).toFixed(2)} MB`
    });

    // ÙØ­Øµ Ø§Ù„Ø­Ø¬Ù…
    if (file.size > MAX_FILE_SIZE) {
      return {
        valid: false,
        error: `Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù (${(file.size / 1024 / 1024 / 1024).toFixed(2)} GB) ÙŠØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ (5 GB)`
      };
    }

    // ÙØ­Øµ Ø§Ù„ØµÙŠØºØ©
    const fileName = file.name.toLowerCase();
    const extension = fileName.split('.').pop() || '';
    const allowedExtensions = ['mp4', 'm4v', 'mov', 'webm', 'mkv', 'avi'];

    if (!allowedExtensions.includes(extension)) {
      return {
        valid: false,
        error: `Ø§Ù„ØµÙŠØºØ© ${extension} ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©. Ø§Ù„ØµÙŠØº Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©: MP4, MOV, WebM, MKV, AVI`
      };
    }

    // ØªØ­Ø°ÙŠØ± Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
    if (file.size > 1024 * 1024 * 1024) {
      const sizeGB = (file.size / 1024 / 1024 / 1024).toFixed(2);
      return {
        valid: true,
        warning: `Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ± (${sizeGB} GB). Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ø¸Ø§Ù… Ø±ÙØ¹ Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ ØªÙ‚Ø³ÙŠÙ… ØªÙ„Ù‚Ø§Ø¦ÙŠ. Ø§Ù„Ø±ÙØ¹ Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø¹Ø¯Ø© Ø¯Ù‚Ø§Ø¦Ù‚.`
      };
    }

    console.log('âœ… [LargeUpload] File validation passed');
    return { valid: true };
  }
}

export const largeVideoUploadService = new LargeVideoUploadService();
